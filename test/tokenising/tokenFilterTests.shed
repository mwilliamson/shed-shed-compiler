module shed/compiler/tokenising/tokenFilterTests;

members {
    testCases
}

import hat.TestCase;
import hat;
import duck.assertThat;
import duck.isList;
import duck.equalTo;

import shed/compiler/tokenising/tokens;
import shed/compiler/tokenising/tokenFilter.filterTokens;
import lop/strings;
    

def assertFilteredTokens fun(inputTokens: List[Token], matcher: Matcher[List[Token]]) =>
    filterTokens(inputTokens)
        .map(fun(filteredTokens: List[Token]) =>
            assertThat(filteredTokens, matcher)
        )
        .valueOrElse(fun() =>
            hat.results.failure("Failed to filter tokens")
        )

val testCases = listOf[TestCase](
    TestCase("whitespace tokens are filtered out", fun() => do {
        return assertFilteredTokens(
            listOf(
                identifier("x"),
                whitespace(" \t"),
                identifier("y")
            ),
            equalTo(listOf(
                identifier("x"),
                identifier("y")
            ))
        );
    }),
    
    TestCase("newline before comment is not significant", fun() => do {
        return assertFilteredTokens(
            listOf(
                whitespace("\n"),
                comment("// asf"),
                whitespace("\n  ")
            ),
            equalTo(emptyList)
        );
    }),

    TestCase("comment tokens are filtered out", fun() => do {
        return assertFilteredTokens(
            listOf(
                comment("// saf")
            ),
            equalTo(emptyList)
        );
    }),
    
    TestCase("new lines are significant at zero indentation", fun() => do {
        return assertFilteredTokens(
            listOf(
                whitespace("\n")
            ),
            equalTo(listOf(
                newline()
            ))
        );
    }),
    
    TestCase("blank lines are ignored", fun() => do {
        return assertFilteredTokens(
            listOf(
                whitespace("\n   \n")
            ),
            equalTo(listOf(
                newline()
            ))
        );
    }),
    
    TestCase("new line followed by whitespace is ignored", fun() => do {
        return assertFilteredTokens(
            listOf(
                whitespace("\n    ")
            ),
            equalTo(emptyList)
        );
    }),
    
    TestCase("indented newline after block start is significant", fun() =>
        assertFilteredTokens(
            listOf(
                symbol("::"),
                whitespace("\n    ")
            ),
            equalTo(listOf(
                symbol("::"),
                indent()
            ))
        )
    ),
    
    TestCase("whitespace can follow block start before newline", fun() =>
        assertFilteredTokens(
            listOf(
                symbol("::"),
                whitespace("  \n    ")
            ),
            equalTo(listOf(
                symbol("::"),
                indent()
            ))
        )
    ),
    
    TestCase("end token creates dedents", fun() =>
        assertFilteredTokens(
            listOf(
                symbol("::"),
                whitespace("\n    "),
                end()
            ),
            equalTo(listOf(
                symbol("::"),
                indent(),
                dedent(),
                end()
            ))
        )
    ),
    
    TestCase("indented newline after block start is ignored if there is a intervening token", fun() => do {
        return assertFilteredTokens(
            listOf(
                symbol("::"),
                symbol("+"),
                whitespace("\n    ")
            ),
            equalTo(listOf(
                symbol("::"),
                symbol("+")
            ))
        );
    }),
    
    TestCase("indented newlines at same indentation after block start are significant", fun() => do {
        return assertFilteredTokens(
            listOf(
                symbol("::"),
                whitespace("\n    "),
                symbol("+"),
                whitespace("\n    ")
            ),
            equalTo(listOf(
                symbol("::"),
                indent(),
                symbol("+"),
                newline()
            ))
        );
    }),
    
    TestCase("newline at previous indentation level causes single dedent", fun() => do {
        return assertFilteredTokens(
            listOf(
                symbol("::"),
                whitespace("\n    "),
                identifier("x"),
                whitespace("\n"),
                identifier("x")
            ),
            equalTo(listOf(
                symbol("::"),
                indent(),
                identifier("x"),
                newline(),
                dedent(),
                newline(),
                identifier("x")
            ))
        );
    }),
    
    TestCase("newline can cause multiple dedents", fun() => do {
        return assertFilteredTokens(
            listOf(
                symbol("::"),
                whitespace("\n  "),
                identifier("x"),
                symbol("::"),
                whitespace("\n    "),
                identifier("x"),
                whitespace("\n"),
                identifier("x")
            ),
            equalTo(listOf(
                symbol("::"),
                indent(),
                identifier("x"),
                symbol("::"),
                indent(),
                identifier("x"),
                newline(),
                dedent(),
                newline(),
                dedent(),
                newline(),
                identifier("x")
            ))
        );
    }),
    
    TestCase("pass keyword allows empty blocks", fun() =>
        assertFilteredTokens(
            listOf(
                symbol("::"),
                whitespace("\n    "),
                keyword("pass"),
                whitespace("\n")
            ),
            equalTo(listOf(
                symbol("::"),
                indent(),
                newline(),
                dedent(),
                newline()
            ))
        )
    )
);

def identifier fun(value: String) =>
    tokens.identifier(value, stringSource())

def whitespace fun(value: String) =>
    tokens.whitespace(value, stringSource())

def symbol fun(value: String) =>
    tokens.symbol(value, stringSource())

def keyword fun(value: String) =>
    tokens.keyword(value, stringSource())

def comment fun(value: String) =>
    tokens.comment(value, stringSource())
    
def newline fun() =>
    tokens.newline(stringSource())

def indent fun() =>
    tokens.indent(stringSource())

def dedent fun() =>
    tokens.dedent(stringSource())

def end fun() =>
    tokens.end(stringSource())

    
def stringSource fun() =>
    strings.createStringSource("", "raw string");
