module shed/compiler/tokenising/tokenFilter;

members::
    filterTokens

import sequences;
import lazySequences;
import lists;
import regex;
import trampolining

import shed/compiler/tokenising/tokens;
import shed/compiler/results

def filterTokens fun(input: Sequence[Token]) => let
    val uncommentedInput = filterComments(input)
    in results.success(lists.reversed(filterTokens2(sequences.nil, uncommentedInput, sequences.nil)))

def filterComments fun(input: Sequence[Token]) => let
    val item = input.currentItem()
    in if sequences.isEmpty(item) then
        sequences.nil
    else
        let val token = item.head()
        in if token.name().equals("whitespace") &&
                nextTokenIsComment(item.tail()) then
            filterComments(pop(item.tail()))
        else if token.name().equals("comment") then
            filterComments(item.tail())
        else
            sequences.cons(item.head(), filterComments(item.tail()))
            

def filterTokens2 fun(accumulator: Sequence[Sequence[Token]], input: Sequence[Token], indentationStack: Sequence[Integer]) =>
    trampolining.trampoline(fun() => filterTokens3(accumulator, input, indentationStack))

def filterTokens3 fun(accumulator: Sequence[Sequence[Token]], input: Sequence[Token], indentationStack: Sequence[Integer]) =>
    if sequences.isEmpty(input) then
        trampolining.stop(lazySequences.concat(accumulator))
    else
        extractNewline(input.currentItem(), indentationStack)
            .map(fun(filtered: Sequence[Token], rest: Sequence[Token], newIndentationStack: Sequence[Integer]) =>
                trampolining.nextFunction(fun() => filterTokens3(sequences.cons(filtered, accumulator), rest, newIndentationStack))
            )

def extractNewline fun(input: SequenceItem[Token], indentationStack: Sequence[Integer]) => let
    val token = input.head()
    val withTail = fun(filtered: Sequence[Token]) =>
        tuple(filtered, input.tail(), indentationStack)
        
    in if isSymbol(token, "::") then
        sequences.head(input.tail()).map(fun(nextToken: Token) =>
            if nextToken.name().equals("whitespace") then
                regex.create("\n( *)$").exec(nextToken.value())
                    .map(fun(regexResult: RegexResult) =>
                        tuple(
                            listOf(
                                tokens.indent(nextToken.source()),
                                token
                            ),
                            input.tail().currentItem().tail(),
                            sequences.cons(regexResult.capture(1).length(), indentationStack)
                        )
                    )
                    .valueOrElse()
            else
                withTail(sequences.singleton(token))
        ).valueOrElse()
        
    else if token.name().equals("whitespace") then
        if regex.create("\n").test(token.value()) then let
        
            val indentationLevel = regex.create("\n( *)$")
                .exec(token.value())
                .map(fun(result: RegexResult) =>
                    result.capture(1).length()
                )
                .valueOrElse(fun() => 0)
            
            val currentIndentationLevel = currentIndentation(indentationStack)
            
            in if indentationLevel.equals(currentIndentationLevel) then
                withTail(sequences.singleton(tokens.newline(token.source())))
            else if indentationLevel.lessThan(currentIndentationLevel) then
                tuple(
                    listOf(tokens.dedent(token.source()), tokens.newline(token.source())),
                    input,
                    pop(indentationStack)
                )
            else
                withTail(sequences.nil)
        else
            withTail(sequences.nil)
            
    else if token.name().equals("keyword") && token.value().equals("pass") then
        withTail(sequences.nil)
    else if token.name().equals("end") && not(sequences.isEmpty(indentationStack)) then
        tuple(sequences.singleton(tokens.dedent(token.source())), input, indentationStack.tail())
    else
        withTail(sequences.singleton(token))

def nextTokenIsComment fun(input: Sequence[Token]) =>
    nextTokenIs(
        fun(token: Token) => token.name().equals("comment"),
        input
    )

def nextTokenIs fun(predicate: Function[Token, Boolean], input: Sequence[Token]) =>
    sequences.head(input)
        .map(predicate)
        .valueOrElse(fun() => false)

def isSymbol fun(token: Token, value: String) =>
    isTokenValue(token, "symbol", value)

def isTokenValue fun(token: Token, type: String, value: String) =>
    token.name().equals(type) && token.value().equals(value)

def currentIndentation fun(indentationStack: Sequence[Integer]) =>
    sequences.head(indentationStack).valueOrElse(fun() => 0)

def pop fun(sequence: Sequence[T]) =>
    sequences.tail(sequence).valueOrElse(fun() => sequences.nil)
