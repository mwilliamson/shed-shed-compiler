module shed.compiler.parsing.parser;

members {
    Parser
}

import lazySequences;

import lop.token.Token;
import shed.compiler.tokenising.tokeniser.Tokeniser;
import lop.results.Success;
import shed.compiler.nodes;

def Parser class() => {
    val tokeniser = Tokeniser();
    
    def filteredParse fun(predicate: Function[Token, Boolean]) =>
        fun(rule: Rule, input: StringSource) =>
            rule(lazySequences.filter(predicate, tokenise(input)))
            
    public val parse = 
        filteredParse(fun(token: Token) => not(token.name().equals("whitespace")));
    
    public val parseWithoutEndToken =
        filteredParse(fun(token: Token) =>
            not(or(token.name().equals("whitespace"), token.name().equals("end"))));
    
    def tokenise fun(input: StringSource) =>
        tokeniser.tokenise(input).toSequence();
}
